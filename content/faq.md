---
title: FAQ
date: 2024-04-23
---

<!-- {{< faq-item text="" >}}
  
{{< /faq-item >}} -->

{{< faq-item text="What inspired you to focus on supporting machine learning, AI safety, and global catastrophic risk creators?" >}}
  Given the advancements in AI, biotechnology, and the explosive hazards of nukes, pandemics, and climate change, there is an immense need to foster awareness of global catastrophic risk (GCRs). By supporting creators in this space, we aim to amplify efforts to ensure that there are more listening ears, engaged minds, and hands steadily tinkering on and exploring how humanity can overcome the precipice we are currently precariously placed atop. We believe humanity can overcome these obstacles and that this requires more hands on deck when it comes to solving this centuries’ greatest challenges. Exciting isn’t it!?
{{< /faq-item >}}

{{< faq-item text="How do you determine which creators to support in this niche?" >}}
  We look for creators who are knowledgeable, passionate, and committed to some area within global catastrophic risk or tangentially connected to the field. This can range from pandemics to climate change, nukes to population ethics, grand futures to ethical AI development, and everything in between. Their work should also be accessible and informative to a broad audience.
{{< /faq-item >}}

{{< faq-item text="What are some of the biggest challenges you face in this role?" >}}
  Our biggest challenges are time restrictions, total work hours, and funding. Through building Pythonic, we are hoping to foster the potential of our projects as well as future projects with partnerships with other global catastrophic risk-focused science communication. Through doing this, we hope to foster the growth of a content ecosystem that can provide routes for both education and engagement in GCR.
{{< /faq-item >}}

{{< faq-item text="What role do you think public awareness plays in mitigating AI risks?" >}}
  Expert-informed public engagement is crucial for a healthy society. Educated and informed citizens can, and already have, begun to advocate for responsible AI practices and support policies that mitigate the catastrophic and existential risks that novel technologies pose. By increasing the number of individuals, across all backgrounds and demographics, who are well informed on the world's most pressing issues, we also grown the diversity and size of the group who are meaningfully participating in these conversations. Democracy works best when more people have a sense of efficacy and are well informed on things that matter. Simple as that.
{{< /faq-item >}}

{{< faq-item text="How do we measure impact?" >}}
  Measuring the direct impact of scientific communication is quite tricky, as an approach more holistic than simple engagement metrics, incorporating aspects such as meaningful engagement, and increased involvement, is required. Accordingly, we not only track the more traditional metrics, like total listening hours, average listening time, subscription/follower count, audience retention, and show ratings, but we also conduct audience surveys and continually explore new ways to understand our audiences. The data we gather are used to aid in our understanding of community growth, what our listeners do and don't like, and a whole lot more.
{{< /faq-item >}}
